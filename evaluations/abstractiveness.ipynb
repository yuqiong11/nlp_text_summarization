{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"abstractiveness.ipynb","provenance":[],"authorship_tag":"ABX9TyOqmt8EREB/VDLtIWEsbmZ0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"jqG_8Du9iApa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616593884665,"user_tz":-60,"elapsed":40557,"user":{"displayName":"Yuqiong Weng","photoUrl":"","userId":"03667284038441978996"}},"outputId":"9d09a3e7-ec08-43f3-e26a-852d01b29cc1"},"source":["# n-gram abstractiveness\n","rouge_avg = load_metric('rouge')\n","ref = []\n","\n","for i in range(len(test_text)):\n","  token_text = tokenizer.batch_encode_plus([test_text.iloc[i]], max_length=max_length-160, truncation=True)['input_ids']\n","  token_text = torch.tensor(token_text)\n","\n","  ref.append(tokenizer.decode(token_text.squeeze(), skip_special_tokens=True))\n","\n","for r, g in zip(ref, gen):\n","  rouge_avg.add(prediction=g,reference=r)\n","\n","score = rouge_avg.compute(rouge_types=['rouge1',\"rouge2\",'rouge3','rougeL'])\n","\n","# n-gram abstractiveness = 1 - # of overlapped n-grams in text and generated summaries/ # of n-grams in generated summaries\n","for i, j in score.items():\n","  print(f\"{i}-gram abtractiveness: {1-j.mid.precision}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rouge1-gram abtractiveness: 0.30985161814637163\n","rouge2-gram abtractiveness: 0.6705021403282289\n","rouge3-gram abtractiveness: 0.7933408891503776\n","rougeL-gram abtractiveness: 0.4437381672494347\n"],"name":"stdout"}]}]}